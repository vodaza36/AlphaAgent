"""
This file is a template for the .env file.

Please copy this file to .env and fill in the values.

For more information about configuration options, please refer to the documentation

"""

# Global configs:
USE_AZURE=False
CHAT_USE_AZURE_TOKEN_PROVIDER=False
EMBEDDING_USE_AZURE_TOKEN_PROVIDER=False
MAX_RETRY=5
RETRY_WAIT_SECONDS=5
FACTOR_MINING_TIMEOUT=10800 # 最大运行时间
USE_LOCAL=True

# LLM API Setting:
OPENAI_BASE_URL=<your_base_url>
OPENAI_API_KEY=<your_api_key>
CHAT_MODEL=<your_chat_model> # e.g., "deepseek-v3"
REASONING_MODEL=<your_reasoning_model> # e.g. "deepseek-reasoner"
EMBEDDING_MODEL=text-embedding-3-small # RAG

CHAT_MAX_TOKENS=4000
CHAT_TEMPERATURE=0.7

# Performance logging (writes perf.log with step timing data):
# ENABLE_PERF_LOG=False